{
 "cells": [
  {
   "source": [
    "### Obtaining a subset of the data from https://nijianmo.github.io/amazon/index.html#complete-data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "source": [
    "### Putting the data in a pandas dataframe. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('Grocery_and_Gourmet_Food_5.json.gz')"
   ]
  },
  {
   "source": [
    "### Subset the data to what we need and store it in dg. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = df[['overall','reviewText']]"
   ]
  },
  {
   "source": [
    "### Cleaning the data. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### (a) handle NaNs. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "overall                 0\n",
       "verified                0\n",
       "reviewTime              0\n",
       "reviewerID              0\n",
       "asin                    0\n",
       "reviewerName          138\n",
       "reviewText            390\n",
       "summary               219\n",
       "unixReviewTime          0\n",
       "vote               985658\n",
       "style              551774\n",
       "image             1134350\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove nulls\n",
    "dg.dropna(inplace=True)"
   ]
  },
  {
   "source": [
    "### (b) add a sentiment column and set it to one if the overall rating was greater than 3 and to zero if the rating was less than 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.loc[dg['overall'] > 3.0, 'sentiment'] = 1\n",
    "dg.loc[dg['overall'] < 3.0, 'sentiment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove any reviews with a neutral rating of 3 stars.\n",
    "dg.dropna(axis=0, how = 'any', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower case to reduce complexity of bag of words matrix. \n",
    "dg['reviewText'] = dg['reviewText'].map(lambda x: x.lower())"
   ]
  },
  {
   "source": [
    "### final data before fitting. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "dg.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 75,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   overall                                         reviewText  sentiment\n",
       "0      5.0                                no adverse comment.        1.0\n",
       "1      5.0                          gift for college student.        1.0\n",
       "2      5.0  if you like strong tea, this is for you. it mi...        1.0\n",
       "3      5.0  love the tea. the flavor is way better than th...        1.0\n",
       "4      5.0  i have searched everywhere until i browsed ama...        1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>reviewText</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>no adverse comment.</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>gift for college student.</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>if you like strong tea, this is for you. it mi...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>love the tea. the flavor is way better than th...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>i have searched everywhere until i browsed ama...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize vectorizer. \n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set X and y. \n",
    "X,y= dg.reviewText, dg.sentiment"
   ]
  },
  {
   "source": [
    "### split the data in train and test sets. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1000, random_state = 42, train_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to bow matrices. \n",
    "X_train_bow, X_test_bow = vectorizer.fit_transform(X_train),vectorizer.transform(X_test)\n"
   ]
  },
  {
   "source": [
    "### The data is ready for fitting models and I am going to be using several models. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SVM linear"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    " svc_lin = svm.SVC(kernel=\"linear\", C=0.025)\n",
    " svc_lin.fit(X_train_bow, y_train)\n",
    " svc_lin.score(X_test_bow,y_test)\n"
   ]
  },
  {
   "source": [
    "### SVM non linear\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.917"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "clf = svm.SVC(gamma = 'auto', C =1)\n",
    "clf.fit(X_train_bow,y_train)\n",
    "clf.score(X_test_bow,y_test)\n"
   ]
  },
  {
   "source": [
    "### Classification Tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train_bow,y_train)\n",
    "clf.score(X_test_bow,y_test)"
   ]
  },
  {
   "source": [
    "### Random Forrest\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "clf = RandomForestClassifier( random_state=0)\n",
    "clf.fit(X_train_bow,y_train)\n",
    "clf.score(X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}